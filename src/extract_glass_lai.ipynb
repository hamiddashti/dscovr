{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "from tqdm import tqdm\n",
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_site(site_info):\n",
    "    i, name, lat, lon = site_info\n",
    "    print(f\"Processing: {name}, i: {i}\")\n",
    "\n",
    "    base_dir = \"/home/hamid/mnt/nas/Hamid/GLASS/EC_SITES/\"\n",
    "    years = np.arange(2002, 2022)\n",
    "    fnames = []\n",
    "    dates = []\n",
    "\n",
    "    for year in years:\n",
    "        dir_path = os.path.join(base_dir, name, str(year))\n",
    "        tif_files = glob.glob(dir_path + \"/*.tif\")\n",
    "        # Check if number of files is exactly 46\n",
    "        if len(tif_files) == 46:\n",
    "            for file in tif_files:\n",
    "                fnames.append(file)\n",
    "                date_part = file.split(\"/\")[-1].split(\".\")[2][1:]\n",
    "                dates.append(datetime.strptime(date_part, \"%Y%j\").date())\n",
    "        else:\n",
    "            print(f\"Warning: {dir_path} does not contain exactly 46 files.\")\n",
    "\n",
    "    lai_tmp = []\n",
    "    for fname in tqdm(fnames, desc=f\"Processing {name}\", unit=\"file\"):\n",
    "        date = dates[fnames.index(fname)]\n",
    "        da = rioxarray.open_rasterio(fname).squeeze().drop(\"band\")\n",
    "        da = da.expand_dims(time=[date])\n",
    "        lai_tmp.append(da.sel(x=lon, y=lat, method=\"nearest\").values * 0.1)\n",
    "\n",
    "    data_frame = pd.DataFrame(lai_tmp, index=dates, columns=[\"LAI\"])\n",
    "    output_dir = \"/home/hamid/mnt/nas/Hamid/GLASS/csv_files/\"\n",
    "    data_frame.to_csv(f\"{output_dir}{name}.csv\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merged_coords_1 = pd.read_csv(\"../data/merged_coords_batch1.csv\")\n",
    "    merged_coords_2 = pd.read_csv(\"../data/merged_coords_batch2.csv\")\n",
    "    merged_coords = pd.concat([merged_coords_1, merged_coords_2], ignore_index=True)\n",
    "\n",
    "    # Prepare the list of arguments for each site\n",
    "    site_info_list = [\n",
    "        (i, merged_coords[\"name\"][i], merged_coords[\"Lat\"][i], merged_coords[\"Lon\"][i])\n",
    "        for i in range(merged_coords.shape[0])\n",
    "    ]\n",
    "\n",
    "    # Get the number of CPU cores\n",
    "    num_cores = os.cpu_count()\n",
    "\n",
    "    # Create a pool of workers and map the process_site function to all sites in parallel\n",
    "    with mp.Pool(processes=num_cores) as pool:\n",
    "        list(\n",
    "            tqdm(\n",
    "                pool.imap(process_site, site_info_list),\n",
    "                total=len(site_info_list),\n",
    "                desc=\"Overall Progress\",\n",
    "            )\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geospatial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
